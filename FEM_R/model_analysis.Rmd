---
title: "FEM Model Analysis"
output:
  html_document:
    df_print: paged
---

This notebook is for debugging purposes. The current plan is to write a Make rule for running this notebook automatically at the end of a model run.

The purpose of this notebook is:
- Present the T-tests altogether in one document.
- Present all transition models in same document.
- Add visualisation for cross-validation 2 output

Do all this for both minimal models and cross-validation.

```{r setup, include=FALSE}
# Need to set up the working directory
workingDir <- "/home/luke/Documents/E_FEM_clean/E_FEM/output/"
knitr::opts_knit$set(root.dir = workingDir)

require(tidyverse)
require(reactable)
require(haven)
require(data.table)
require(reshape2)
require(ggplot2)
require(plyr)

```

```{r include=FALSE}

# Need this code block for reactable tables to be rendered properly in HTML
# Fix from here: https://www.gitmemory.com/issue/glin/reactable/43/618802061
htmltools::tagList(
  reactR::html_dependency_react(),
  reactR::html_dependency_reacttools(),
  reactable::reactable(iris)
)

# function to rename the dataframes, so we can run in an lapply()
rename_first_var <- function(testCSV, prefix) {
  testCSV[,1] <- paste0(testCSV[,1], '_', prefix)
  return(testCSV)
}

# function for shortening column names
shorten_columns <- function(testCSV) {
  testCSV <- testCSV %>%
                rename_at(vars(starts_with('fem_mean_wave')), funs(sub('fem_mean_wave', 'FEM_', .))) %>%
                rename_at(vars(starts_with('elsa_mean_wave')), funs(sub('elsa_mean_wave', 'ELSA_', .))) %>%
                rename_at(vars(starts_with('p_value_wave')), funs(sub('p_value_wave', 'P_Value_', .))) %>%
                dplyr::rename('Variable' = variable)
}

```

<!-- First, we will collect and present all the T-tests together. We will add the prefix 'min_' or 'cv_' onto the variable names so we don't get mixed up. -->

```{r include=FALSE}
# names for T-tests directory and filename stem
min <- "ELSA_minimal/T-tests/"
stem <- "minimal_all_waves_"

# Read in all the T-test csv files
min_uw <- read.csv(paste0(min, stem, "unweighted.csv"))
min_demog <- read.csv(paste0(min, stem, "demog.csv"))
min_binhlth <- read.csv(paste0(min, stem, "binhlth.csv"))
min_binecon <- read.csv(paste0(min, stem, "binecon.csv"))
min_risk <- read.csv(paste0(min, stem, "risk.csv"))

# Collect in a list to do some formatting
min_list <- list(min_uw, min_demog, min_binhlth, min_binecon, min_risk)
# Add prefix 'min_' onto every variable name for clarity
min_list <- lapply(min_list, rename_first_var, prefix='min')
# Rename columns to be more succinct
min_list <- lapply(min_list, shorten_columns)
# Replace na with 0
min_list <- lapply(min_list, function(x) { x[is.na(x)] <- 0; x} )

```

```{r include=FALSE}
# names for T-tests directory and filename stem
CV1 <- "ELSA_CV1/T-tests/"
stem <- "CV1_all_waves_"
# Read in files
cv_uw <- read.csv(paste0(CV1, stem, "unweighted.csv"))
cv_demog <- read.csv(paste0(CV1, stem, "demog.csv"))
cv_binhlth <- read.csv(paste0(CV1, stem, "binhlth.csv"))
cv_binecon <- read.csv(paste0(CV1, stem, "binecon.csv"))
cv_risk <- read.csv(paste0(CV1, stem, "risk.csv"))
# Now collect into list and rename vars and cols for clarity
cv_list <- list(cv_uw, cv_demog, cv_binhlth, cv_binecon, cv_risk)
cv_list <- lapply(cv_list, rename_first_var, prefix='CV')
cv_list <- lapply(cv_list, shorten_columns)
cv_list <- lapply(cv_list, function(x) { x[is.na(x)] <- 0; x} )
```

<!-- Both Minimal and Cross-validation T-tests are now renamed and collected into a separate list object each. We will now combine like tests together (i.e. demog with demog, binhlth with binhlth). -->

```{r include=FALSE}
# Set up vector with all p-value column names. Require these for table formatting
pValNames <- c('P_Value_3', 'P_Value_4', 'P_Value_5', 'P_Value_6', 'P_Value_7', 'P_Value_8')
```

<!-- Lets build the combined tables now. -->

```{r include=FALSE}
# Row bind to collect both dfs together
uw <- rbind(min_list[[1]], cv_list[[1]])
# Reorder rows in alphabetical order. This ensures that like variables are clumped together
uw <- arrange(uw, Variable)

# demog
demog <- rbind(min_list[[2]], cv_list[[2]])
demog <- arrange(demog, Variable)

# binhlth
binhlth <- rbind(min_list[[3]], cv_list[[3]])
binhlth <- arrange(binhlth, Variable)

# binecon
binecon <- rbind(min_list[[4]], cv_list[[4]])
binecon <- arrange(binecon, Variable)

# risk
risk <- rbind(min_list[[5]], cv_list[[5]])
risk <- arrange(risk, Variable)
```


# Reactable Tables

The [reactable](https://glin.github.io/reactable/index.html) package has the ability to include lots of complex styling, such as additional colour, formatting and even inline graphs built dynamically from the input data.

For the purpose of this document, we are going to include a sticky first column (so we can always see the variable names whilst scrolling), a colour gradient from white to green based on the P Value (low = white, high = green), and a red cell background for any P values of 0.

```{r echo = FALSE}
## This block will define the logic for creating the tables with Reactable
# The tables are formatted exaclty the same for each group of vars so makes sense to define this only once

# createTTT - create T-Test Table
# Have a default column definition, to handle the basic formatting, then specific formatting for the first column (Variable) and P Val cols
createTTT <- function(t) {
  # To enable a 'sticky' first column, that always shows as you scroll across the table
  stickyStyle <- list(position = "sticky", left = 0, background = "#fff", zIndex = 1,
                      borderRight = "1px solid #eee")
  
  # Define a colour ramp to use for P Value cell gradients
  greenPal <- function(x) rgb(colorRamp(c("#ffffff", "#008000"))(x), maxColorValue = 255)
  
  # Add in the green colour gradient for P Value cells. Also add a red block for value of 0
  pValColDef <- colDef(
    style = function(value) {
      color <- greenPal(value)
      if (value == 0) {
        color <- "#ff4c4c"
      }
      list(background = color)
    },
    minWidth = 110
  )
  
  pValColDef2 <- colDef(
    style = function(value) {
      if (value >= 0.05) {
        color <- "#4ca64c"
      }
      if (value < 0.05) {
        color <- "#ff6666"
      }
      list(background = color)
    },
    minWidth = 110
  )
  
  res <- reactable(t,
            defaultColDef = colDef(
              header = function(value) gsub('_', ' ', value, fixed=TRUE),
              cell = function(value) format(value, nsmall = 2),
              align = 'center'
            ),
            columns = list(
              Variable = colDef(
                  minWidth = 160,
                  style = stickyStyle,
                  headerStyle = stickyStyle),
              P_Value_1 = pValColDef2,
              P_Value_2 = pValColDef2,
              P_Value_3 = pValColDef2,
              P_Value_4 = pValColDef2,
              P_Value_5 = pValColDef2,
              P_Value_6 = pValColDef2,
              P_Value_7 = pValColDef2,
              P_Value_8 = pValColDef2
            ),
            bordered = TRUE,
            highlight = TRUE,
            striped = TRUE)
  
  return(res)
}

```

### Unweighted (Died)

```{r echo = FALSE}
# Create the actual table!
uwTab <- createTTT(uw)
uwTab
```

### Demographics

```{r echo = FALSE}
# Create the actual table!
demogTab <- createTTT(demog)
demogTab
```

### Binary Health
```{r echo = FALSE}
# Create the actual table!
binhlthTab <- createTTT(binhlth)
binhlthTab
```
### Binary Economic
```{r echo = FALSE}
# Create the actual table!
bineconTab <- createTTT(binecon)
bineconTab
```
### Risk Behaviours
```{r echo = FALSE}
# Create the actual table!
riskTab <- createTTT(risk)
riskTab
```

# Cross Validation 2 - 'Handover' plots (Still WIP need fixing)

```{r echo = FALSE}
vis_CV2_prev <- function(long, CV2) {
  
  # Keep only waves 1 - 4
  longC <- subset(long, wave < 5)
  longC <- as.data.table(longC)
  
  # Replace all NA with 0
  longC[is.na(longC)] <- 0
  
  # Have to drop r*clust vars as they contain strings
  longC <- select(longC, -contains('clust'))
  
  # Now get the weighted mean by wave of every column based on cwtresp
  l2 <- longC[ , lapply(.SD,weighted.mean,w=cwtresp), by = list(wave)]
  
  # ELSA_long is now processed to the point where we can start extracting and combining variables
  # Better start by adding year to l2 and reordering the columns
  l2$year <- seq(from=2002, to = 2008, by = 2)
  setcolorder(l2, c('year', 'wave'))
  
  # Now lets extract chronic disease variables from both dataframes and do a row combine
  # Start with cancre, diabe, hearte
  cd_l2 <- select(l2, c(year, age, cancre, diabe, hearte, lunge, smoken, bmi, employed, anyadl)) #, anyiadl, adl1, adl2, adl3p))
  cd_CV2 <- select(CV2, c(year, a_age_all, p_cancre_all, p_diabe_all, 
                            p_hearte_all, p_lunge_all, p_smoken_all, 
                            a_bmi_all, p_employed_all,  p_anyadl_all))
                            #, p_anyiadl_all p_adl1_all, p_adl2_all, p_adl3p_all))
  
  CV2_rename <- cd_CV2 %>% dplyr::rename('age' = a_age_all,
                                        'cancre' = p_cancre_all, 
                                        'diabe' = p_diabe_all, 
                                        'hearte' = p_hearte_all,
                                        'lunge' = p_lunge_all,
                                        'smoken' = p_smoken_all,
                                        'bmi' = a_bmi_all,
                                        'employed' = p_employed_all,
                                        'anyadl' = p_anyadl_all)
                                        #'anyiadl' = p_anyiadl_all)
                                        #'adl1' = p_adl1_all,
                                        #'adl2' = p_adl2_all,
                                        #'adl3p' = p_adl3p_all)
  
  combine <- rbind(cd_l2, CV2_rename)
  
  melted <- melt(combine, id.var = 'year', value.name = 'Prevalence')
  
  ggplot(data = melted, aes(x = year, y = Prevalence, color = variable)) +
          geom_line() +
          facet_wrap(. ~ variable, scales = "free")
          #theme(panel.spacing.x = unit(1.5, 'lines')) +
          #labs(title = 'Prevalence of Chronic Disease', x = 'Year', y = 'Prevalence')
}

# Load in whole stock pop, plus the CV2 summary output file
long <- read_dta('../input_data/ELSA_long.dta')
CV2 <- read_dta('ELSA_CV2/ELSA_CV2_summary.dta')

vis_CV2_prev(long, CV2)
```

# Intervention Scenarios

### Base Initial Prevalence of Chronic Disease

```{r echo = FALSE}
visInitBasePrev <- function(base) {
  
  cdMelted <- base %>%
                select(c('year', 'p_cancre_all', 'p_diabe_all', 'p_hearte_all')) %>%
                dplyr::rename('Cancer' = p_cancre_all, 'Diabetes' = p_diabe_all, 'Heart Disease' = p_hearte_all) %>%
                filter(year == 2012) %>%
                melt(id.var = 'year', value.name = 'Prevalence') %>%
                subset(select = -year)
  
  ggplot(data=cdMelted, aes(x=variable, y=Prevalence)) +
          geom_bar(stat = 'identity') +
          labs(title='Initial Prevalence', x='Prevalence', y='Chronic Disease')
}

baseline <- read_dta('ELSA_Baseline/ELSA_Baseline_summary.dta')

visInitBasePrev(baseline)
```

### Baseline Projections

```{r echo = FALSE}
visProjectedBaselineCD <- function(base) {
  
  # Extract vars, rename, and melt to put it in better format for graphing with ggplot2
  cdMelted <- base %>%
                select(c('year', 'p_cancre_all', 'p_diabe_all', 'p_hearte_all')) %>%
                dplyr::rename('Cancer' = p_cancre_all, 'Diabetes' = p_diabe_all, 'Heart Disease' = p_hearte_all) %>%
                melt(id.var='year', value.name = 'Prevalence')
  
  # Create the tiled plot of disease prevalence
  ggplot(data=cdMelted, aes(x=year, y=Prevalence)) +
            geom_line() +
            facet_grid(. ~ variable) +
            theme(panel.spacing.x = unit(1.5, 'lines')) +
            labs(title = 'Prevalence of Chronic Disease', x = 'Year', y = 'Prevalence')
}

baseline <- read_dta('ELSA_Baseline/ELSA_Baseline_summary.dta')

visProjectedBaselineCD(baseline)
```

### Baseline Projections by Subpopulation

```{r echo = FALSE}
visProjectedBySubpop <- function(base, cd, path='/home/luke/Documents/E_FEM_clean/Deliverables/E-FEM_Paper/figures/Scenario_1/') {
  
  if(cd == 'cancre') {
    dis <- 'Cancer'
  } else if(cd == 'diabe') {
    dis <- 'Diabetes'
  } else if(cd == 'hearte') {
    dis <- 'Heart Disease'
  }
  
  # Generate varnames
  all <- paste0('p_', cd, '_all')
  # age
  a5564 <- paste0('p_', cd, '_5564')
  a6574 <- paste0('p_', cd, '_6574')
  a7584 <- paste0('p_', cd, '_7584')
  a85p <- paste0('p_', cd, '_85p')
  
  ageMelt <- base %>%
              select(c('year', a5564, a6574, a7584, a85p)) %>%
              dplyr::rename('55 to 64' = a5564, '65 to 74' = a6574, '75 to 64' = a7584, '85+' = a85p) %>%
              melt(id.var = 'year', value.name = 'Prevalence')
  
  ggplot(data=ageMelt, aes(x=year, y=Prevalence, color = variable)) +
          geom_line() +
          labs(title = dis, x = 'Year', y = 'Prevalence')
}

baseline <- read_dta('ELSA_Baseline/ELSA_Baseline_summary.dta')

visProjectedBySubpop(baseline, cd = 'cancre')
visProjectedBySubpop(baseline, cd = 'diabe')
visProjectedBySubpop(baseline, cd = 'hearte')
```

# Github Reporting

It would be nice if we could copy paste tables directly from this document into a github issue. For this reason, we will look into a package that can print tables directly into markdown or something similar, which we can then place straight into a Github issue.

```{r}

#kable


```


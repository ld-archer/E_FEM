---
title: "FEM Model Analysis"
output: html_notebook
---

This notebook is for debugging purposes. The current plan is to write a Make rule for running this notebook automatically at the end of a model run.

The purpose of this notebook is:
- Present the T-tests altogether in one document.
- Present all transition models in same document.
- Add visualisation for cross-validation 2 output

Do all this for both minimal models and cross-validation.

```{r setup, include=FALSE}
# Need to set up the working directory
workingDir <- "/home/luke/Documents/E_FEM_clean/E_FEM/output/COMPLETE/"
knitr::opts_knit$set(root.dir = workingDir)

require(tidyverse)
require(reactable)
require(haven)
require(data.table)
require(reshape2)
require(ggplot2)
require(plyr)

```

```{r include=FALSE}

# Need this code block for reactable tables to be rendered properly in HTML
# Fix from here: https://www.gitmemory.com/issue/glin/reactable/43/618802061
htmltools::tagList(
  reactR::html_dependency_react(),
  reactR::html_dependency_reacttools(),
  reactable::reactable(iris)
)

# function to rename the dataframes, so we can run in an lapply()
rename_first_var <- function(testCSV, prefix) {
  testCSV[,1] <- paste0(testCSV[,1], '_', prefix)
  return(testCSV)
}

# function for shortening column names
shorten_columns <- function(testCSV) {
  testCSV <- testCSV %>%
                rename_at(vars(starts_with('fem_mean_wave')), funs(sub('fem_mean_wave', 'FEM_', .))) %>%
                rename_at(vars(starts_with('elsa_mean_wave')), funs(sub('elsa_mean_wave', 'ELSA_', .))) %>%
                rename_at(vars(starts_with('p_value_wave')), funs(sub('p_value_wave', 'P_Value_', .))) %>%
                dplyr::rename('Variable' = variable)
}

```

<!-- First, we will collect and present all the T-tests together. We will add the prefix 'min_' or 'cv_' onto the variable names so we don't get mixed up. -->

```{r include=FALSE}
# names for T-tests directory and filename stem
min <- "ELSA_minimal/T-tests/"
stem <- "minimal_all_waves_"

# Read in all the T-test csv files
min_uw <- read.csv(paste0(min, stem, "unweighted.csv"))
min_demog <- read.csv(paste0(min, stem, "demog.csv"))
min_binhlth <- read.csv(paste0(min, stem, "binhlth.csv"))
min_binecon <- read.csv(paste0(min, stem, "binecon.csv"))
min_cntecon <- read.csv(paste0(min, stem, "cntecon.csv"))
min_risk <- read.csv(paste0(min, stem, "risk.csv"))

# Collect in a list to do some formatting
min_list <- list(min_uw, min_demog, min_binhlth, min_binecon, min_cntecon, min_risk)
# Add prefix 'min_' onto every variable name for clarity
min_list <- lapply(min_list, rename_first_var, prefix='min')
# Rename columns to be more succinct
min_list <- lapply(min_list, shorten_columns)
# Replace na with 0
min_list <- lapply(min_list, function(x) { x[is.na(x)] <- 0; x} )

```

```{r include=FALSE}
# names for T-tests directory and filename stem
CV1 <- "ELSA_CV1/T-tests/"
stem <- "CV1_all_waves_"
# Read in files
cv_uw <- read.csv(paste0(CV1, stem, "unweighted.csv"))
cv_demog <- read.csv(paste0(CV1, stem, "demog.csv"))
cv_binhlth <- read.csv(paste0(CV1, stem, "binhlth.csv"))
cv_binecon <- read.csv(paste0(CV1, stem, "binecon.csv"))
cv_cntecon <- read.csv(paste0(CV1, stem, "cntecon.csv"))
cv_risk <- read.csv(paste0(CV1, stem, "risk.csv"))
# Now collect into list and rename vars and cols for clarity
cv_list <- list(cv_uw, cv_demog, cv_binhlth, cv_binecon, cv_cntecon, cv_risk)
cv_list <- lapply(cv_list, rename_first_var, prefix='CV')
cv_list <- lapply(cv_list, shorten_columns)
cv_list <- lapply(cv_list, function(x) { x[is.na(x)] <- 0; x} )
```

<!-- Both Minimal and Cross-validation T-tests are now renamed and collected into a separate list object each. We will now combine like tests together (i.e. demog with demog, binhlth with binhlth). -->

```{r include=FALSE}
# Set up vector with all p-value column names. Require these for table formatting
pValNames <- c('P_Value_3', 'P_Value_4', 'P_Value_5', 'P_Value_6', 'P_Value_7', 'P_Value_8', 'P_Value_9')
```

<!-- Lets build the combined tables now. -->

```{r include=FALSE}
# Row bind to collect both dfs together
uw <- rbind(min_list[[1]], cv_list[[1]])
# Reorder rows in alphabetical order. This ensures that like variables are clumped together
uw <- arrange(uw, Variable)

# demog
demog <- rbind(min_list[[2]], cv_list[[2]])
demog <- arrange(demog, Variable)

# binhlth
binhlth <- rbind(min_list[[3]], cv_list[[3]])
binhlth <- arrange(binhlth, Variable)

# binecon
binecon <- rbind(min_list[[4]], cv_list[[4]])
binecon <- arrange(binecon, Variable)

# cntecon
cntecon <- rbind(min_list[[5]], cv_list[[5]])
cntecon <- arrange(cntecon, Variable)

# risk
risk <- rbind(min_list[[6]], cv_list[[6]])
risk <- arrange(risk, Variable)
```


# Reactable Tables

The [reactable](https://glin.github.io/reactable/index.html) package has the ability to include lots of complex styling, such as additional colour, formatting and even inline graphs built dynamically from the input data.

For the purpose of this document, we are going to include a sticky first column (so we can always see the variable names whilst scrolling), a colour gradient from white to green based on the P Value (low = white, high = green), and a red cell background for any P values of 0.

```{r echo = FALSE}
## This block will define the logic for creating the tables with Reactable
# The tables are formatted exactly the same for each group of vars so makes sense to define this only once

# createTTT - create T-Test Table
# Have a default column definition, to handle the basic formatting, then specific formatting for the first column (Variable) and P Val cols
createTTT <- function(t) {
  # To enable a 'sticky' first column, that always shows as you scroll across the table
  stickyStyle <- list(position = "sticky", left = 0, background = "#fff", zIndex = 1,
                      borderRight = "1px solid #eee")
  
  # Define a colour ramp to use for P Value cell gradients
  greenPal <- function(x) rgb(colorRamp(c("#ffffff", "#008000"))(x), maxColorValue = 255)
  
  # Add in the green colour gradient for P Value cells. Also add a red block for value of 0
  pValColDef <- colDef(
    style = function(value) {
      color <- greenPal(value)
      if (value == 0) {
        color <- "#ff4c4c"
      }
      list(background = color)
    },
    minWidth = 110
  )
  
  pValColDef2 <- colDef(
    style = function(value) {
      if (value >= 0.05) {
        color <- "#4ca64c"
      }
      if (value < 0.05) {
        color <- "#ff6666"
      }
      list(background = color)
    },
    minWidth = 110
  )
  
  res <- reactable(t,
            defaultColDef = colDef(
              header = function(value) gsub('_', ' ', value, fixed=TRUE),
              cell = function(value) format(value, nsmall = 2),
              align = 'center'
            ),
            columns = list(
              Variable = colDef(
                  minWidth = 160,
                  style = stickyStyle,
                  headerStyle = stickyStyle),
              P_Value_1 = pValColDef2,
              P_Value_2 = pValColDef2,
              P_Value_3 = pValColDef2,
              P_Value_4 = pValColDef2,
              P_Value_5 = pValColDef2,
              P_Value_6 = pValColDef2,
              P_Value_7 = pValColDef2,
              P_Value_8 = pValColDef2,
              P_Value_9 = pValColDef2
            ),
            bordered = TRUE,
            highlight = TRUE,
            striped = TRUE)
  
  return(res)
}

```

### Unweighted (Died)

```{r echo = FALSE}
# Create the actual table!
uwTab <- createTTT(uw)
uwTab
```

### Demographics

```{r echo = FALSE}
# Create the actual table!
demogTab <- createTTT(demog)
demogTab
```

### Binary Health
```{r echo = FALSE}
# Create the actual table!
binhlthTab <- createTTT(binhlth)
binhlthTab
```
### Binary Economic
```{r echo = FALSE}
# Create the actual table!
bineconTab <- createTTT(binecon)
bineconTab
```
### Count Economic
```{r echo = FALSE}
# Create the actual table!
cnteconTab <- createTTT(cntecon)
cnteconTab
```
### Risk Behaviours
```{r echo = FALSE}
# Create the actual table!
riskTab <- createTTT(risk)
riskTab
```

# Intervention Scenarios

### Base Initial Prevalence of Chronic Disease

```{r echo = FALSE}
visInitBasePrev <- function(base) {
  
  cdMelted <- base %>%
                select(c('year', 'p_cancre_all', 'p_diabe_all', 'p_hearte_all')) %>%
                dplyr::rename('Cancer' = p_cancre_all, 'Diabetes' = p_diabe_all, 'Heart Disease' = p_hearte_all) %>%
                filter(year == 2012) %>%
                reshape2::melt(id.var = 'year', value.name = 'Prevalence') %>%
                subset(select = -year)
  
  ggplot(data=cdMelted, aes(x=variable, y=Prevalence)) +
          geom_bar(stat = 'identity') +
          labs(title='Initial Prevalence', x='Prevalence', y='Chronic Disease')
}

baseline <- read_dta('ELSA_core_base/ELSA_core_base_summary.dta')

visInitBasePrev(baseline)
```

### Baseline Projections

```{r echo = FALSE}
visProjectedBaselineCD <- function(base) {
  
  # Extract vars, rename, and melt to put it in better format for graphing with ggplot2
  cdMelted <- base %>%
                select(c('year', 'p_cancre_all', 'p_diabe_all', 'p_hearte_all')) %>%
                dplyr::rename('Cancer' = p_cancre_all, 'Diabetes' = p_diabe_all, 'Heart Disease' = p_hearte_all) %>%
                reshape2::melt(id.var='year', value.name = 'Prevalence')
  
  # Create the tiled plot of disease prevalence
  ggplot(data=cdMelted, aes(x=year, y=Prevalence)) +
            geom_line() +
            facet_grid(. ~ variable) +
            theme(panel.spacing.x = unit(1.5, 'lines')) +
            labs(title = 'Prevalence of Chronic Disease', x = 'Year', y = 'Prevalence')
}

baseline <- read_dta('ELSA_core_base/ELSA_core_base_summary.dta')

visProjectedBaselineCD(baseline)
```

### Survival Curve

```{r echo = FALSE}
cohort <- read_dta('ELSA_core_cohort/ELSA_core_cohort_summary.dta')

cohort$age <- (cohort$year - 2012) + 50

cohort$survival <- cohort$m_endpop_all / cohort$m_endpop_all[1]
cohort$survival_m <- cohort$m_endpop_m / cohort$m_endpop_m[1]
cohort$survival_f <- cohort$m_endpop_f / cohort$m_endpop_f[1]

# plot up survival curve
ggplot(cohort, aes(x=age, y=survival)) +
        geom_line(col='black', size=0.3) +
        labs(title='Cohort Survival: All', y='Survival', x='Age')
```

# AgeUK Almanac External Validation

'The Age UK almanac of disease profiles in later life', published in October 2015, contains information on the prevalence of major diseases, conditions, and syndromes affecting older people in England, broken down by age and sex. 

```{r echo = FALSE}
#AgeUK
male_au <- read.csv('../../FEM_R/AgeUK_Validation/AgeUK-chronDisease-MALE_CI.csv')
female_au <- read.csv('../../FEM_R/AgeUK_Validation/AgeUK-chronDisease-FEMALE_CI.csv')

# FEM 2014 summary
FEM <- read_dta('ELSA_AgeUK_core_valid/ELSA_AgeUK_core_valid_summary.dta')

# Keep only year 2014 from FEM summary
FEM <- filter(FEM, year == 2014)

# Specify the age groups to extract from FEM
ages <- c('6064', '6569', '7074', '7579', '8084', '8589', '9094', '9599', '100p')
# Add m and f for male and female variables
m_ages <- paste0('m_', ages)
f_ages <- paste0('f_', ages)

# Collect the age suffixes into a vector
keep_vars <- c(m_ages, f_ages)
# Now set up the chronic diseases in a list so we can create a bigger list with all of them produced
diseases <- c('hibpe', 'stroke', 'diabe', 'demene', 'asthmae')

# Don't like using loops but this one was just too simple to bother with figuring out the apply version
final <- c()
ticker <- 1
# Generating the column (variable) names we want to keep in a loop
for(item in diseases) {
  for(anotherItem in keep_vars) {
    final[ticker] <- paste0('p_', item, '_', anotherItem)
    ticker <- ticker + 1
  }
}

# Keep the right vars using varnames generated in loop
FEM <- FEM %>%
          select(c('year', all_of(final)))

# Rename some vars to remove 'p_' before merging
FEM <- FEM %>%
          rename_at(vars(starts_with('p_')),
                    funs(str_replace(., 'p_', ''))) %>%
          select(!year)

pivoted.FEM <- pivot_longer(data = FEM,
                            cols = hibpe_m_6064:asthmae_f_100p,
                            names_to = c('Condition', 'Gender', 'Age_Group'),
                            names_sep = '_')

# Convert value from fraction to percentage
pivoted.FEM$value <- pivoted.FEM$value * 100
# Set gender codes to upper case
pivoted.FEM$Gender <- toupper(pivoted.FEM$Gender)

# Rename variables for the pivot
male_au <- male_au %>%
                dplyr::rename(M_6064_total = M_60.64_total, M_6064_lower = M_60.64_l, M_6064_upper = M_60.64_u, 
                              M_6569_total = M_65.69_total, M_6569_lower = M_65.69_l, M_6569_upper = M_65.69_u,
                              M_7074_total = M_70.74_total, M_7074_lower = M_70.74_l, M_7074_upper = M_70.74_u,
                              M_7579_total = M_75.79_total, M_7579_lower = M_75.79_l, M_7579_upper = M_75.79_u,
                              M_8084_total = M_80.84_total, M_8084_lower = M_80.84_l, M_8084_upper = M_80.84_u,
                              M_8589_total = M_85.89_total, M_8589_lower = M_85.89_l, M_8589_upper = M_85.89_u,
                              M_9094_total = M_90.94_total, M_9094_lower = M_90.94_l, M_9094_upper = M_90.94_u,
                              M_9599_total = M_95.99_total, M_9599_lower = M_95.99_l, M_9599_upper = M_95.99_u,
                              M_100p_total = M_Over.100_total, M_100p_lower = M_Over.100_l, M_100p_upper = M_Over.100_u) %>%
                select(-M_Total_total, -M_Total_l, -M_Total_u)

female_au <- female_au %>%
                dplyr::rename(F_6064_total = F_60.64_total, F_6064_lower = F_60.64_l, F_6064_upper = F_60.64_u, 
                              F_6569_total = F_65.69_total, F_6569_lower = F_65.69_l, F_6569_upper = F_65.69_u,
                              F_7074_total = F_70.74_total, F_7074_lower = F_70.74_l, F_7074_upper = F_70.74_u,
                              F_7579_total = F_75.79_total, F_7579_lower = F_75.79_l, F_7579_upper = F_75.79_u,
                              F_8084_total = F_80.84_total, F_8084_lower = F_80.84_l, F_8084_upper = F_80.84_u,
                              F_8589_total = F_85.89_total, F_8589_lower = F_85.89_l, F_8589_upper = F_85.89_u,
                              F_9094_total = F_90.94_total, F_9094_lower = F_90.94_l, F_9094_upper = F_90.94_u,
                              F_9599_total = F_95.99_total, F_9599_lower = F_95.99_l, F_9599_upper = F_95.99_u,
                              F_100p_total = F_Over.100_total, F_100p_lower = F_Over.100_l, F_100p_upper = F_Over.100_u) %>%
                select(-F_Total_total, -F_Total_l, -F_Total_u)

# Now need to reshape these datasets to long format
pivoted.male <- pivot_longer(data = male_au,
                             cols = M_6064_total:M_100p_upper,
                             names_to = c('Gender', 'Age_Group', 'Type'),
                             names_sep = '_')

pivoted.female <- pivot_longer(data = female_au,
                             cols = F_6064_total:F_100p_upper,
                             names_to = c('Gender', 'Age_Group', 'Type'),
                             names_sep = '_')

# Now bring the confidence intervals back into columns because ggplot needs that format
# to plot them. Seems pretty daft to be honest but thats what we've got
pivoted.male <- pivot_wider(pivoted.male,
                            names_from = Type,
                            values_from = value)
pivoted.female <- pivot_wider(pivoted.female,
                            names_from = Type,
                            values_from = value)

# Now row bind these frames together, combining male and female data
ageUK <-rbind(pivoted.male, pivoted.female)

# Now drop the heart problems from original ageUK and replace with aggregate
ageUK <- filter(ageUK, Condition != 'Coronary Heart Disease', Condition != 'Heart Failure', Condition != 'Atrial Fibrillation')

# Finally, add column to specify that this is ageUK data
ageUK$source <- "ageUK"

# REMOVE CONDITIONS FROM ageUK THAT ARE NOT IN FEM (may change in future)
#ageUK <- filter(ageUK, Condition != c('Asthma', 'Depression', 'Severe Mental Health Condition'))
ageUK <- filter(ageUK, Condition != 'Depression', Condition != 'Severe Mental Health Conditions')
ageUK <- filter(ageUK, Condition != 'Cancer, recent', Condition != 'COPD')

# Make copy
newFEM <- pivoted.FEM

# Rename all the conditions to fit ageUK
# NOTE: Lung disease is not a perfect match, as ageUK only contains info on COPD
#       Therefore only validation from this will be that FEM is higher than ageUK
#newFEM$Condition <- gsub("hearte", "Heart Problems", newFEM$Condition)
newFEM$Condition <- gsub("hibpe", "Hypertension", newFEM$Condition)
newFEM$Condition <- gsub("stroke", "Stroke", newFEM$Condition)
newFEM$Condition <- gsub("diabe", "Diabetes", newFEM$Condition)
#newFEM$Condition <- gsub("lunge", "Lung Disease (COPD)", newFEM$Condition)
#newFEM$Condition <- gsub("cancre", "Cancer", newFEM$Condition)
newFEM$Condition <- gsub("demene", "Dementia", newFEM$Condition)
newFEM$Condition <- gsub("asthmae", "Asthma", newFEM$Condition)

# Add column to specify this is FEM data
newFEM$source <- "FEM"
newFEM$total <- newFEM$value
newFEM <- select(newFEM, -value)

# Add column to specify this is FEM data
newFEM$source <- "FEM"
# Add column to specify these are all totals (no confidence intervals)
newFEM$lower <- NA
newFEM$upper <- NA

# Now row bind the datasets
combined <- rbind(newFEM, ageUK)
# Specify factor levels for age group
combined$Age_Group <- factor(combined$Age_Group, levels = c('6064', '6569', '7074', '7579', '8084', '8589', '9094', '9599', '100p'))
# Sort
combined <- arrange(combined, source, Condition, Gender, Age_Group)

# Function to filter the combined dataset and visualise
visAgeUKValid <- function(data, cd, gender, path = '/home/luke/Documents/E_FEM_clean/Deliverables/E-FEM_Paper/figures/validation/ageUK') {
  
  if(gender == 'M') {
    full_gender <- 'Male'
  }
  else if(gender == 'F') {
    full_gender <- 'Female'
  }
  
  # filter by gender and condition
  data <- data %>%
            filter(Gender == gender) %>%
            filter(Condition == cd)
  
  # now plot!
  p <- ggplot(data = data, aes(x = Age_Group, y = total)) +
          geom_bar(aes(fill = source), stat = "identity", position = position_dodge2()) +
          geom_errorbar(aes(ymin = lower, ymax = upper), position = position_dodge2(width = 1, padding = 0.5)) +
          labs(title = paste(cd, full_gender, sep = ' '), x = 'Age Group', y = 'Proportion')
  
  p <- p + scale_fill_grey(start = .2, end = .7)
  # Save plot into in E-FEM_Paper/figures/
  #ggsave(filename = paste0(cd, '_', gender, '.png'),
  #      plot = p,
  #      path = path,
  #      width = 7,
  #      height = 5)
  
  return(p)
}

```

```{r echo=FALSE}
# Collect all conditions (and both genders) into a list, and apply the function above to that list
cd_list <- unique(combined$Condition)
gender_list <- unique(combined$Gender)

for(cd in cd_list) {
  for(gen in gender_list) {
    plot <- visAgeUKValid(combined, cd, gen)
    print(plot)
  } 
}
```

# Smoking

```{r echo=FALSE}
FEM_base <- read_dta('ELSA_core_base/ELSA_core_base_summary.dta')

# Smoking prevalence stats
smok.5059 <- 15.2
smok.60p <- 10.2

# FEM summary, filter for 2018 and 60p
#FEM.smok <- FEM_sum
FEM.smok <- FEM_base
FEM.smok <- FEM.smok %>%
                filter(year == 2018) %>%
                select(contains('smoken')) %>%
                select(contains('60p'), contains('5059')) %>%
                select(contains('p_'))

FEM.smok <- FEM.smok * 100

smok.combined <- data.frame(FEM = FEM.smok[1,1], AgeUK = 10.2)
smok.combined <- data.frame(source = c('FEM', 'FEM', 'Observed', 'Observed'), age = c('50 - 59', '60+', '50 - 59', '60+'), value = c(FEM.smok[1,2], FEM.smok[1,1], 15.2, 10.2))

smok.plot <-ggplot(data = smok.combined, aes(x = age, y = value)) +
                geom_bar(aes(fill = source), stat = "identity", position = "dodge") +
                labs(title = 'Prevalence of Smoking (2018)', x = ' ', y = 'Prevalence (%)')

#ggsave(filename = 'smoking_prev_2018.png',
#       plot = smok.plot,
#       path = '/home/luke/Documents/E_FEM_clean/Deliverables/E-FEM_Paper/figures/validation/',
#       width = 7,
#       height = 5)

smok.plot

```


# Github Reporting

It would be nice if we could copy paste tables directly from this document into a github issue. For this reason, we will look into a package that can print tables directly into markdown or something similar, which we can then place straight into a Github issue.

```{r}

#kable


```

